{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU_NUM = 1\n",
    "GPU_NUM = str(GPU_NUM)\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\" \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = GPU_NUM\n",
    "\n",
    "import shutil\n",
    "import warnings\n",
    "import contextlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "from IPython.display import clear_output\n",
    "\n",
    "warnings.filterwarnings(action='ignore')\n",
    "plt.style.use(plt.style.available[-3])\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "\n",
    "torch.set_default_dtype(torch.float32)\n",
    "\n",
    "GPU = torch.device('cuda')\n",
    "CPU = torch.device('cpu')\n",
    "print(torch.cuda.is_available(), ': ', torch.cuda.get_device_name(0))\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils import *\n",
    "from networks.networks import *\n",
    "from options.hyper_parameters import HP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp = HP()\n",
    "hp.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet(shape=True)\n",
    "x = torch.zeros([1, 1, 28, 28])\n",
    "with torch.no_grad(): res = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet()\n",
    "train_set = Dataset_Temp(hp, phase='train')\n",
    "valid_set = Dataset_Temp(hp, phase='valid')\n",
    "train_loader = DataLoader(dataset=train_set, shuffle=True, batch_size=hp.batch_size, \n",
    "                          num_workers=2, pin_memory=True)\n",
    "valid_loader = DataLoader(dataset=valid_set, shuffle=True, batch_size=hp.batch_size, \n",
    "                          num_workers=2, pin_memory=True)\n",
    "data_loader = [train_loader, valid_loader]\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-2)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=hp.scheduler_step, gamma=hp.scheduler_gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if hp.multi_gpu: model = nn.DataParallel(model)\n",
    "model = model.to(hp.device)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "print(f'{\"Model\":<20}: {hp.name}')\n",
    "\n",
    "BCE_func = BCE()\n",
    "MAE_func = MAE()\n",
    "ACC_func = ACC()\n",
    "\n",
    "loss_keys = ['BCE', 'MAE']\n",
    "rate_keys = ['ACC']\n",
    "\n",
    "epoch_s, epoch_e = 1, hp.epochs+1\n",
    "if hp.epoch_load!=None:\n",
    "    last_point = torch.load(f'../res/{hp.name}/model/last_point.pt')\n",
    "    model.load_state_dict(last_point['model'].state_dict())\n",
    "    optimizer.load_state_dict(last_point['optimizer'].state_dict())\n",
    "    epoch_s = hp.epoch_load + 1\n",
    "    epoch_save = last_point['epoch']\n",
    "    print(f'※ Continual Learning: {epoch_save} Epoch ※')\n",
    "    \n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "loss_epoch = torch.zeros([epoch_e, 2, len(loss_keys)])\n",
    "rate_epoch = torch.zeros([epoch_e, 2, len(rate_keys)])\n",
    "for epoch in range(epoch_s, epoch_e):\n",
    "    \n",
    "    for i, phase in enumerate(['Train', 'Valid']):\n",
    "        if phase=='Train':\n",
    "            model.train()\n",
    "            context_manager = contextlib.nullcontext()\n",
    "        if phase=='Valid':\n",
    "            model.eval()\n",
    "            context_manager = torch.no_grad()\n",
    "        \n",
    "        loss_batch = torch.zeros([len(data_loader[i]), len(loss_keys)])\n",
    "        rate_batch = torch.zeros([len(data_loader[i]), len(rate_keys)])\n",
    "        with context_manager:\n",
    "            for k, data in enumerate(data_loader[i]):\n",
    "                X, y = data[0].to(hp.device), data[1].to(hp.device)\n",
    "                \n",
    "                with torch.cuda.amp.autocast(enabled=True):\n",
    "                    # Forward\n",
    "                    p = model(X)\n",
    "                    \n",
    "                    # Loss\n",
    "                    BCE_res = BCE_func(p, y)\n",
    "                    MAE_res = MAE_func(p, y)\n",
    "                    \n",
    "                    # Final Loss\n",
    "                    loss_final = BCE_res+MAE_res\n",
    "                    \n",
    "                    loss_batch[k, 0] = BCE_res.detach()\n",
    "                    loss_batch[k, 1] = MAE_res.detach()\n",
    "                    \n",
    "                if phase=='Train':\n",
    "                    optimizer.zero_grad()\n",
    "                    scaler.scale(loss_final).backward()\n",
    "                    scaler.step(optimizer)\n",
    "                    scaler.update()\n",
    "                \n",
    "                # Rate\n",
    "                with torch.no_grad():\n",
    "                    ACC_res = ACC_func(p, y)\n",
    "                    rate_batch[k, 0] = ACC_res\n",
    "        \n",
    "        loss_epoch[epoch, i] = torch.mean(loss_batch.cpu(), axis=0)\n",
    "        rate_epoch[epoch, i] = torch.mean(rate_batch.cpu(), axis=0)\n",
    "        \n",
    "    # Scheduler\n",
    "    if scheduler is not None: scheduler.step()\n",
    "    \n",
    "    # Monitoring\n",
    "    es_loss = es(loss_epoch, epoch, inverse=False)\n",
    "    es_rate = es(rate_epoch, epoch, inverse=True)\n",
    "    \n",
    "    if epoch==1:\n",
    "        print(f'===== Loss Monitoring =====')\n",
    "        print(f'Loss: {loss_keys}', end=' ')\n",
    "        print(f'rate: {rate_keys}', end=' ')\n",
    "        print(f'(Train, Valid)')\n",
    "    if epoch%hp.monitoring_cycle==0:\n",
    "        print(f'{epoch:5.0f}/{hp.epochs:5.0f}', end=' ')\n",
    "        for l in range(len(loss_keys)):\n",
    "            loss_train = loss_epoch[epoch, 0, l]\n",
    "            loss_valid = loss_epoch[epoch, 1, l]\n",
    "            loss_ratio = (loss_train/loss_valid)*100\n",
    "            print(f'({loss_train:6.4f}, {loss_valid:6.4f})', end=f' {es_loss[l]} ')\n",
    "        print('*', end=' ')\n",
    "        for l in range(len(rate_keys)):\n",
    "            rate_train = rate_epoch[epoch, 0, l]\n",
    "            rate_valid = rate_epoch[epoch, 1, l]\n",
    "            rate_ratio = (rate_train/rate_valid)*100\n",
    "            print(f'({rate_train:6.4f}, {rate_valid:6.4f})', end=f' {es_rate[l]} ')\n",
    "        print()\n",
    "        \n",
    "        # Save\n",
    "        history = {'loss':loss_epoch, \n",
    "                   'rate':rate_epoch, \n",
    "                   'loss_keys':loss_keys, \n",
    "                   'rate_keys':rate_keys}\n",
    "        if epoch-1==hp.epoch_load:\n",
    "            history['loss'][:hp.epoch_load+1] = last_point['history']['loss'][:hp.epoch_load+1]\n",
    "            history['rate'][:hp.epoch_load+1] = last_point['history']['rate'][:hp.epoch_load+1]\n",
    "        \n",
    "        if epoch%hp.save_cycle==0:\n",
    "            torch.save(history, f'{hp.path_model}/history.pt')\n",
    "            torch.save(model, f'{hp.path_model}/model_{epoch}.pt')\n",
    "            last_point = {'epoch':epoch, \n",
    "                          'history':history, \n",
    "                          'model':model, \n",
    "                          'optimizer':optimizer}\n",
    "            # torch.save(last_point, f'{hp.path_model}/last_point.pt')\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
